{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for SMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np                      # linear algebra\n",
    "import pandas as pd                     # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn import preprocessing;\n",
    "from sklearn import cross_validation;\n",
    "from sklearn import linear_model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of following files:\n",
    "\n",
    "• prices.csv: raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n",
    "\n",
    "• prices-split-adjusted.csv: same as prices, but there have been added adjustments for splits.\n",
    "\n",
    "• securities.csv: general description of each company with division on sectors\n",
    "\n",
    "• fundamentals.csv: metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prices-split-adjusted.csv', '.DS_Store', 'fundamentals.csv', 'SMP_Regression.ipynb', 'prices.csv', 'securities.csv']\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "a = os.listdir(\"/Users/rounakbose/Desktop/SMP_Code\")\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, forecast_col, forecast_out, test_size):\n",
    "    \n",
    "    label = df[forecast_col].shift(-forecast_out);       #creating new column called label with the last 5 rows are nan\n",
    "    X = np.array(df[[forecast_col]]);                           #creating the feature array\n",
    "    X = preprocessing.scale(X)                                 #processing the feature array\n",
    "    X_lately = X[-forecast_out:]                                 #creating the column i want to use later in the predicting method\n",
    "    X = X[:-forecast_out]                                           # X that will contain the training and testing\n",
    "    label.dropna(inplace=True);                                #dropping na values\n",
    "    y = np.array(label)                                               # assigning Y\n",
    "    \n",
    "    #cross validation \n",
    "    X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, y, test_size=test_size) \n",
    "\n",
    "    response = [X_train, X_test, Y_train, Y_test, X_lately];\n",
    "    return response;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the csv file\n",
    "df = pd.read_csv(\"/Users/rounakbose/Desktop/SMP_Code/prices.csv\") \n",
    "\n",
    "#choosing stock symbol\n",
    "df=df[df.symbol=='GOOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_col = 'close'                       #choosing which column to forecast\n",
    "forecast_out = 10                             #how far to forecast \n",
    "test_size = 0.2;                                 #the size of my test set\n",
    "\n",
    "#calling the method where the cross validation and data preperation is in\n",
    "X_train, X_test, Y_train, Y_test , X_lately =prepare_data(df,forecast_col,forecast_out,test_size); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = linear_model.LinearRegression();           #initializing linear regression model\n",
    "\n",
    "learner.fit(X_train,Y_train);                                     #training the linear regression model\n",
    "score=learner.score(X_test,Y_test);                      #testing the linear regression model\n",
    "\n",
    "forecast= learner.predict(X_lately);                       #set that will contain the forecasted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_score': 0.9069184892214378} \n",
      "\n",
      "{'test_score': 0.9069184892214378, 'forecast_set': array([782.43807629, 785.59613057, 787.65811276, 785.93049742,\n",
      "       782.86535987, 781.61140104, 783.13470099, 777.09728689,\n",
      "       774.99811516, 764.80884477])}\n"
     ]
    }
   ],
   "source": [
    "response={};                                                          #creating json object\n",
    "response['test_score']=score; \n",
    "\n",
    "print(response, '\\n');\n",
    "\n",
    "response['forecast_set']=forecast;\n",
    "\n",
    "print(response);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
